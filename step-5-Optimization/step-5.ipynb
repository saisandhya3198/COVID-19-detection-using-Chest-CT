{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac36bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "import math\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b35cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>Dissimilarity</th>\n",
       "      <th>Homogenity</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.867882</td>\n",
       "      <td>18.958477</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>1128.419845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018590</td>\n",
       "      <td>0.895155</td>\n",
       "      <td>16.439161</td>\n",
       "      <td>0.099919</td>\n",
       "      <td>734.834338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020157</td>\n",
       "      <td>0.904695</td>\n",
       "      <td>16.137180</td>\n",
       "      <td>0.115214</td>\n",
       "      <td>782.162402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112826</td>\n",
       "      <td>0.943806</td>\n",
       "      <td>12.886319</td>\n",
       "      <td>0.287135</td>\n",
       "      <td>841.671875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112826</td>\n",
       "      <td>0.943806</td>\n",
       "      <td>12.886319</td>\n",
       "      <td>0.287135</td>\n",
       "      <td>841.671875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.942602</td>\n",
       "      <td>13.027313</td>\n",
       "      <td>0.297123</td>\n",
       "      <td>853.388410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.942602</td>\n",
       "      <td>13.027313</td>\n",
       "      <td>0.297123</td>\n",
       "      <td>853.388410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.124367</td>\n",
       "      <td>0.940236</td>\n",
       "      <td>13.142286</td>\n",
       "      <td>0.303815</td>\n",
       "      <td>879.873708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122299</td>\n",
       "      <td>0.937820</td>\n",
       "      <td>13.223241</td>\n",
       "      <td>0.294432</td>\n",
       "      <td>866.365342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.043661</td>\n",
       "      <td>0.941740</td>\n",
       "      <td>10.756582</td>\n",
       "      <td>0.218150</td>\n",
       "      <td>523.159879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.035821</td>\n",
       "      <td>0.877649</td>\n",
       "      <td>14.102854</td>\n",
       "      <td>0.195065</td>\n",
       "      <td>1176.618356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.864969</td>\n",
       "      <td>14.786417</td>\n",
       "      <td>0.194068</td>\n",
       "      <td>1262.386565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.925565</td>\n",
       "      <td>13.425566</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>708.767717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.038005</td>\n",
       "      <td>0.930392</td>\n",
       "      <td>10.811024</td>\n",
       "      <td>0.254268</td>\n",
       "      <td>646.260335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.036314</td>\n",
       "      <td>0.918097</td>\n",
       "      <td>11.145854</td>\n",
       "      <td>0.243536</td>\n",
       "      <td>704.046198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.952583</td>\n",
       "      <td>12.364296</td>\n",
       "      <td>0.237208</td>\n",
       "      <td>620.878076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.292624</td>\n",
       "      <td>0.950399</td>\n",
       "      <td>8.859006</td>\n",
       "      <td>0.425449</td>\n",
       "      <td>404.278912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.230201</td>\n",
       "      <td>0.915811</td>\n",
       "      <td>12.667815</td>\n",
       "      <td>0.334264</td>\n",
       "      <td>597.367003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.071269</td>\n",
       "      <td>0.877579</td>\n",
       "      <td>18.986836</td>\n",
       "      <td>0.169372</td>\n",
       "      <td>979.873893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.966776</td>\n",
       "      <td>7.486344</td>\n",
       "      <td>0.336345</td>\n",
       "      <td>283.366388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.099863</td>\n",
       "      <td>0.966657</td>\n",
       "      <td>7.335199</td>\n",
       "      <td>0.353884</td>\n",
       "      <td>309.726316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.961480</td>\n",
       "      <td>7.852854</td>\n",
       "      <td>0.306576</td>\n",
       "      <td>287.551181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.075627</td>\n",
       "      <td>0.950979</td>\n",
       "      <td>8.244464</td>\n",
       "      <td>0.314604</td>\n",
       "      <td>329.440699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.023776</td>\n",
       "      <td>0.869120</td>\n",
       "      <td>21.776513</td>\n",
       "      <td>0.125916</td>\n",
       "      <td>1905.239604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.040981</td>\n",
       "      <td>0.950378</td>\n",
       "      <td>13.437869</td>\n",
       "      <td>0.186999</td>\n",
       "      <td>627.869094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.097310</td>\n",
       "      <td>0.934831</td>\n",
       "      <td>16.521100</td>\n",
       "      <td>0.356990</td>\n",
       "      <td>1458.771100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.046410</td>\n",
       "      <td>0.961206</td>\n",
       "      <td>10.468258</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>551.712844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.059966</td>\n",
       "      <td>0.976625</td>\n",
       "      <td>9.069205</td>\n",
       "      <td>0.313886</td>\n",
       "      <td>489.874323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.047932</td>\n",
       "      <td>0.983359</td>\n",
       "      <td>7.272207</td>\n",
       "      <td>0.269020</td>\n",
       "      <td>252.631582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.049753</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>7.842335</td>\n",
       "      <td>0.290596</td>\n",
       "      <td>299.851193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.042032</td>\n",
       "      <td>0.971986</td>\n",
       "      <td>9.343319</td>\n",
       "      <td>0.260984</td>\n",
       "      <td>407.031065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Energy  Correlation  Dissimilarity  Homogenity     Contrast  class_label\n",
       "0   0.019349     0.867882      18.958477    0.099115  1128.419845            0\n",
       "1   0.018590     0.895155      16.439161    0.099919   734.834338            0\n",
       "2   0.020157     0.904695      16.137180    0.115214   782.162402            0\n",
       "3   0.112826     0.943806      12.886319    0.287135   841.671875            0\n",
       "4   0.112826     0.943806      12.886319    0.287135   841.671875            0\n",
       "5   0.119517     0.942602      13.027313    0.297123   853.388410            0\n",
       "6   0.119517     0.942602      13.027313    0.297123   853.388410            0\n",
       "7   0.124367     0.940236      13.142286    0.303815   879.873708            0\n",
       "8   0.122299     0.937820      13.223241    0.294432   866.365342            0\n",
       "9   0.043661     0.941740      10.756582    0.218150   523.159879            0\n",
       "10  0.035821     0.877649      14.102854    0.195065  1176.618356            0\n",
       "11  0.039594     0.864969      14.786417    0.194068  1262.386565            0\n",
       "12  0.041365     0.925565      13.425566    0.194008   708.767717            0\n",
       "13  0.038005     0.930392      10.811024    0.254268   646.260335            0\n",
       "14  0.036314     0.918097      11.145854    0.243536   704.046198            0\n",
       "15  0.043004     0.952583      12.364296    0.237208   620.878076            1\n",
       "16  0.292624     0.950399       8.859006    0.425449   404.278912            1\n",
       "17  0.230201     0.915811      12.667815    0.334264   597.367003            1\n",
       "18  0.071269     0.877579      18.986836    0.169372   979.873893            1\n",
       "19  0.103459     0.966776       7.486344    0.336345   283.366388            1\n",
       "20  0.099863     0.966657       7.335199    0.353884   309.726316            1\n",
       "21  0.075459     0.961480       7.852854    0.306576   287.551181            1\n",
       "22  0.075627     0.950979       8.244464    0.314604   329.440699            1\n",
       "23  0.023776     0.869120      21.776513    0.125916  1905.239604            1\n",
       "24  0.040981     0.950378      13.437869    0.186999   627.869094            1\n",
       "25  0.097310     0.934831      16.521100    0.356990  1458.771100            1\n",
       "26  0.046410     0.961206      10.468258    0.276189   551.712844            1\n",
       "27  0.059966     0.976625       9.069205    0.313886   489.874323            1\n",
       "28  0.047932     0.983359       7.272207    0.269020   252.631582            1\n",
       "29  0.049753     0.980399       7.842335    0.290596   299.851193            1\n",
       "30  0.042032     0.971986       9.343319    0.260984   407.031065            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.drop(columns = 'Index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fa26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'class_label')\n",
    "y = df['class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6f5f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=1234)\n",
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc70ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f629398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining various steps required for the genetic algorithm\n",
    "def initilization_of_population(size,n_feat):\n",
    "    population = []\n",
    "    for i in range(size):\n",
    "        chromosome = np.ones(n_feat,dtype=np.bool)\n",
    "        chromosome[:int(0.3*n_feat)]=False\n",
    "        np.random.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "def fitness_score(population):\n",
    "    scores = []\n",
    "    for chromosome in population:\n",
    "        clf.fit(X_train.iloc[:,chromosome],y_train)\n",
    "        predictions = clf.predict(X_test.iloc[:,chromosome])\n",
    "        scores.append(accuracy_score(y_test,predictions))\n",
    "    scores, population = np.array(scores), np.array(population) \n",
    "    inds = np.argsort(scores)\n",
    "    return list(scores[inds][::-1]), list(population[inds,:][::-1])\n",
    "\n",
    "def selection(pop_after_fit,n_parents):\n",
    "    population_nextgen = []\n",
    "    for i in range(n_parents):\n",
    "        population_nextgen.append(pop_after_fit[i])\n",
    "    return population_nextgen\n",
    "\n",
    "def crossover(pop_after_sel):\n",
    "    population_nextgen=pop_after_sel\n",
    "    for i in range(len(pop_after_sel)):\n",
    "        child=pop_after_sel[i]\n",
    "        child[3:7]=pop_after_sel[(i+1)%len(pop_after_sel)][3:7]\n",
    "        population_nextgen.append(child)\n",
    "    return population_nextgen\n",
    "\n",
    "def mutation(pop_after_cross,mutation_rate):\n",
    "    population_nextgen = []\n",
    "    for i in range(0,len(pop_after_cross)):\n",
    "        chromosome = pop_after_cross[i]\n",
    "        for j in range(len(chromosome)):\n",
    "            if random.random() < mutation_rate:\n",
    "                chromosome[j]= not chromosome[j]\n",
    "        population_nextgen.append(chromosome)\n",
    "    #print(population_nextgen)\n",
    "    return population_nextgen\n",
    "\n",
    "def generations(size,n_feat,n_parents,mutation_rate,n_gen,X_train,\n",
    "                                   X_test, y_train, y_test):\n",
    "    best_chromo= []\n",
    "    best_score= []\n",
    "    population_nextgen=initilization_of_population(size,n_feat)\n",
    "    for i in range(n_gen):\n",
    "        scores, pop_after_fit = fitness_score(population_nextgen)\n",
    "        print(scores[:2])\n",
    "        pop_after_sel = selection(pop_after_fit,n_parents)\n",
    "        pop_after_cross = crossover(pop_after_sel)\n",
    "        population_nextgen = mutation(pop_after_cross,mutation_rate)\n",
    "        best_chromo.append(pop_after_fit[0])\n",
    "        best_score.append(scores[0])\n",
    "    return best_chromo,best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb39690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6b4f1b4716f3>:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  chromosome = np.ones(n_feat,dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n",
      "[0.9, 0.9]\n",
      "[0.8, 0.8]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "Accuracy score after genetic algorithm is= 1.0\n"
     ]
    }
   ],
   "source": [
    "chromo,score=generations(size=31,n_feat=5,n_parents=3,mutation_rate=0.10,\n",
    "                     n_gen=10,X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n",
    "clf.fit(X_train.iloc[:,chromo[-1]],y_train)\n",
    "predictions = clf.predict(X_test.iloc[:,chromo[-1]])\n",
    "print(\"Accuracy score after genetic algorithm is= \"+str(accuracy_score(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ff297e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromo[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841285d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
